{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9194113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from scipy import stats\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import xesmf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import esmpy as ESMF\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.interpolate import CubicSpline\n",
    "import time\n",
    "import pyart\n",
    "import cmocean\n",
    "import gsw\n",
    "import subprocess\n",
    "experiment = \"diurnal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9093aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outline_nep_domain(ax,clon,clat):\n",
    "    #NEP DOMAIN OUTLINE\n",
    "    ax.plot(clon[0,:],clat[0,:],linewidth=1.5,color='k',transform=ccrs.PlateCarree(),zorder=42)\n",
    "    ax.plot(clon[:,0],clat[:,0],linewidth=1.5,color='k',transform=ccrs.PlateCarree(),zorder=42)\n",
    "    ax.plot(clon[-1,:],clat[-1,:],linewidth=1.5,color='k',transform=ccrs.PlateCarree(),zorder=42)\n",
    "    ax.plot(clon[:,-1],clat[:,-1],linewidth=1.5,color='k',transform=ccrs.PlateCarree(),zorder=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec29350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deBoyer_mld():\n",
    "    \n",
    "    deBoyer_fil = deBoyer_dir + mld_fil\n",
    "    fid = nc.Dataset(deBoyer_fil)\n",
    "    lat = fid.variables['lat'][:].squeeze()\n",
    "    lon = fid.variables['lon'][:].squeeze()\n",
    "    clon = (lon[:-1] + lon[1:])/2\n",
    "    clat = (lat[:-1] + lat[1:])/2            \n",
    "    clon = np.insert(np.insert(clon,0,2*clon[0]-clon[1]),-1,2*clon[-1]-clon[-2])\n",
    "    clat = np.insert(np.insert(clat,0,2*clat[0]-clat[1]),-1,2*clat[-1]-clat[-2])\n",
    "    ref_mld = fid.variables['mld_dr003'][:].squeeze()\n",
    "    \n",
    "    lons,lats = np.meshgrid(lon,lat)\n",
    "    chuk_mask = lats>66\n",
    "    \n",
    "    return lat,lon,clon,clat,ref_mld,chuk_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f457d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mld(clon,clat,lon,lat,mld,vmin,vmax,cmap,norm,c_inc):\n",
    "    ax = fig.add_subplot(spec[nrow,ncol], projection=ccrs.PlateCarree(central_longitude=-100))\n",
    "    C = ax.pcolormesh(clon, clat, mld,cmap=cmap, norm=norm,transform=ccrs.PlateCarree())\n",
    "    \n",
    "    levels = np.arange(vmin,vmax+c_inc/2,c_inc)\n",
    "    CS = ax.contour(lon,lat,mld,levels, colors='k', transform=ccrs.PlateCarree())\n",
    "    CS.monochrome = True\n",
    "    plt.draw()\n",
    "    #print(levels)    \n",
    "    land_50m = cfeature.NaturalEarthFeature('physical', 'land', '50m',facecolor='blanchedalmond')\n",
    "    ax.add_feature(land_50m,zorder=50)\n",
    "    ax.coastlines('50m',zorder=50)\n",
    "    outline_nep_domain(ax,nep_clon,nep_clat)\n",
    "\n",
    "    # ADDING GRID LINES AND GRID LABELS \n",
    "    gl = ax.gridlines(draw_labels=annotate_plots)\n",
    "    \n",
    "    gl.xlocator = mticker.FixedLocator([180, -150, -120])\n",
    "    gl.ylocator = mticker.FixedLocator([25, 55])\n",
    "    \n",
    "    if annotate_plots:\n",
    "        gl.xlabel_style = {'size': 20}\n",
    "        gl.ylabel_style = {'size': 20}\n",
    "        gl.bottom_labels = True\n",
    "        gl.top_labels = False\n",
    "\n",
    "        if ncol>0:\n",
    "            gl.left_labels = False\n",
    "        \n",
    "        if ncol<2:\n",
    "            gl.right_labels = False\n",
    "            \n",
    "    plt.setp(ax.spines.values(), linewidth=2,zorder=100)\n",
    "    \n",
    "    # COLORBARS\n",
    "    if nrow == len(comp_prods)-1:\n",
    "        pos = ax.get_position()\n",
    "        cbar_x = pos.x0\n",
    "        \n",
    "        pos_ref = plt.gcf().axes[3].get_position()\n",
    "        cbar_h = .1*pos_ref.height\n",
    "        cbar_y = pos_ref.y0 -.25*pos_ref.height\n",
    "        \n",
    "        if ncol == 1:\n",
    "            cax = fig.add_axes([pos_ref.x0, cbar_y, 2*pos.width, cbar_h])\n",
    "            cbar = plt.colorbar(C,cax=cax,orientation='horizontal',extend='both')\n",
    "            cbar.ax.set_xticks(levels[::2])\n",
    "            cax.plot([levels]*2, [0, 1], 'k')\n",
    "            if annotate_plots:\n",
    "                cbar.ax.tick_params(labelsize=16)\n",
    "                cax.set_xlabel('Mixed Layer Depth (meters)',fontsize=20)\n",
    "            else:\n",
    "                cax.set_xticklabels([])\n",
    "                \n",
    "        elif ncol == 3:\n",
    "            cax = fig.add_axes([pos.x0, cbar_y, pos.width, cbar_h])\n",
    "            cbar = plt.colorbar(C,cax=cax,orientation='horizontal',extend='both')\n",
    "            cbar.ax.set_xticks(levels[::2])\n",
    "            cax.plot([levels[levels>=0]]*2, [0, 1], 'k')\n",
    "            cax.plot([levels[levels<0]]*2, [0, 1], '--k')\n",
    "            if annotate_plots:\n",
    "                cbar.ax.tick_params(labelsize=16)\n",
    "                cax.set_xlabel('Difference (meters)',fontsize=20)\n",
    "            else:\n",
    "                cax.set_xticklabels([])\n",
    "                \n",
    "    if annotate_plots:\n",
    "        if ncol == 3:\n",
    "            stats_text = 'Bias: ' + f'{mean_bias:.2f}' + '\\nRMSE: ' + f'{rmse:.2f}' + '\\nMedAE: ' + f'{medae:.2f}' + '\\nR: ' + f'{corr[0]:.2f}' \n",
    "            ax.text(.03, .05, stats_text, ha=\"left\", va=\"bottom\", size=26, bbox=stats_box_props,transform=ax.transAxes)\n",
    "   \n",
    "        # Titles\n",
    "        if ncol == 0:\n",
    "            title_text = 'NEP10k'\n",
    "        elif ncol == 1:\n",
    "            if nrow == 0:\n",
    "                title_text = 'de Boyer Montégut'\n",
    "            else:\n",
    "                title_text = 'GLORYS12'\n",
    "        else:\n",
    "            if nrow == 0:\n",
    "                title_text = 'NEP10k - de Boyer Montégut'\n",
    "            else:\n",
    "                title_text = 'NEP10k - GLORYS12'\n",
    "        \n",
    "        ax.set_title(title_text, fontsize=28)\n",
    "        ax.text(160,65, plot_labels[nlab], fontsize=25, ha='center', va='center',\n",
    "                transform=ccrs.PlateCarree(),zorder=55)          \n",
    "    \n",
    "    # SET AXES EXTENT\n",
    "    ax.set_extent([np.min(nep_clon),np.max(nep_clon), \n",
    "                   np.min(nep_clat), 70], crs=ccrs.PlateCarree())  \n",
    "    plt.setp(ax.spines.values(), linewidth=2,zorder=100)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d630bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regrid_obj(src_clon,src_clat,src_lsm,dst_clon,dst_clat):\n",
    "    # Make 2D coordinates for remapping\n",
    "    if len(src_clon.shape)<2:\n",
    "        src_clon,src_clat = np.meshgrid(src_clon,src_clat)\n",
    "        \n",
    "    if len(dst_clon.shape)<2:\n",
    "        dst_clon,dst_clat = np.meshgrid(dst_clon,dst_clat)\n",
    "    \n",
    "    sourcegrid = ESMF.Grid(np.array(src_lsm.shape), staggerloc = ESMF.StaggerLoc.CORNER,coord_sys = ESMF.CoordSys.SPH_DEG)\n",
    "    sourcegrid.add_item(ESMF.GridItem.MASK,[ESMF.StaggerLoc.CENTER])\n",
    "    grid_mask = sourcegrid.get_item(ESMF.GridItem.MASK)\n",
    "    grid_mask[...] = src_lsm.astype(np.int32) \n",
    "\n",
    "    source_lon = sourcegrid.get_coords(0, staggerloc=ESMF.StaggerLoc.CORNER)\n",
    "    source_lat = sourcegrid.get_coords(1, staggerloc=ESMF.StaggerLoc.CORNER)\n",
    "\n",
    "    source_lon[...] = src_clon\n",
    "    source_lat[...] = src_clat\n",
    "\n",
    "    sourcefield = ESMF.Field(sourcegrid, name = 'src_field')\n",
    "    srcfracfield = ESMF.Field(sourcegrid, 'srcfracfield')\n",
    "        \n",
    "    destgrid = ESMF.Grid(np.array(dst_clon[1:,1:].shape), staggerloc = ESMF.StaggerLoc.CORNER, coord_sys = ESMF.CoordSys.SPH_DEG)\n",
    "\n",
    "    dest_clon = destgrid.get_coords(0,staggerloc=ESMF.StaggerLoc.CORNER)\n",
    "    dest_clat = destgrid.get_coords(1,staggerloc=ESMF.StaggerLoc.CORNER)\n",
    "\n",
    "    dest_clon[...] = dst_clon\n",
    "    dest_clat[...] = dst_clat\n",
    "\n",
    "    destfield = ESMF.Field(destgrid, name = 'dest_field')\n",
    "\n",
    "    # DEFINE INTERPOLATION FUNCTION\n",
    "    regrid = ESMF.Regrid(sourcefield, destfield,regrid_method = ESMF.RegridMethod.CONSERVE,\n",
    "                     src_mask_values=np.array([0], dtype=np.int32),src_frac_field=srcfracfield,\n",
    "                     norm_type=ESMF.NormType.FRACAREA,unmapped_action = ESMF.UnmappedAction.IGNORE)\n",
    "\n",
    "    return sourcefield, destfield, regrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4d0ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(nep_val_stats, comp_val_stats, area_val):\n",
    "    # CALCULATE STATISTICS\n",
    "    nan_idx = ~np.isnan(nep_val_stats)*~np.isnan(comp_val_stats)\n",
    "    \n",
    "    # Mean Bias\n",
    "    mean_bias = np.nanmean((nep_val_stats-comp_val_stats)[nan_idx])\n",
    "    if print_stats:\n",
    "        print('MEAN BIAS:', mean_bias)\n",
    "\n",
    "    # Mean Bias Area Weighted\n",
    "    mean_bias = np.nansum(((nep_val_stats*area_val)[nan_idx]-(comp_val_stats*area_val)[nan_idx])/np.nansum(area_val[nan_idx]))\n",
    "    if print_stats:\n",
    "        print('AREA-WEIGHTED MEAN BIAS:', mean_bias)\n",
    "\n",
    "    # RMSE \n",
    "    rmse = np.sqrt(np.mean(((nep_val_stats-comp_val_stats)**2)[nan_idx]))\n",
    "    if print_stats:\n",
    "        print('RMSE:', rmse)\n",
    "\n",
    "    # RMSE Area weighted\n",
    "    rmse = np.sqrt(np.sum((((nep_val_stats-comp_val_stats)**2)*area_val)[nan_idx]/np.sum(area_val[nan_idx])))\n",
    "    if print_stats:\n",
    "        print('AREA-WEIGHTED RMSE:', rmse)\n",
    "        \n",
    "    # Median absolute error\n",
    "    medae = np.nanmedian(np.abs(nep_val_stats-comp_val_stats)[nan_idx])\n",
    "    if print_stats:\n",
    "        print('MEDIAN ABSOLUTE ERROR:', medae)\n",
    "\n",
    "    # Correlation\n",
    "    corr = stats.pearsonr(nep_val_stats[nan_idx].ravel(), comp_val_stats[nan_idx].ravel())\n",
    "    if print_stats:\n",
    "        print('CORRELATION:', corr)\n",
    "    \n",
    "    return mean_bias, rmse, medae, corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10bb1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds(src_model):\n",
    "    \n",
    "    # CONSTRUCT FILE NAME\n",
    "    ncfil = (product_dict[src_model]['dir'] + product_dict[src_model]['ncfil'])\n",
    "            \n",
    "    print(ncfil)\n",
    "            \n",
    "    # Open as xarray dataset\n",
    "    ds = xr.open_dataset(ncfil,decode_times=False)\n",
    "        \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eddf1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(src_model,ds):\n",
    " \n",
    "    if src_model == 'dBM':\n",
    "        lon = ds.lon.values\n",
    "        lat = ds.lat.values\n",
    "        \n",
    "    elif src_model == 'GLORYS12':\n",
    "   \n",
    "        lon = ds.longitude.values\n",
    "        lat = ds.latitude.values\n",
    "                    \n",
    "    # REGULARLY SPACED LAT/LON, can extrapolate outer corner bounds\n",
    "    clon = (lon[:-1] + lon[1:])/2\n",
    "    clat = (lat[:-1] + lat[1:])/2            \n",
    "    clon = np.insert(np.insert(clon,0,2*clon[0]-clon[1]),-1,2*clon[-1]-clon[-2])\n",
    "    clat = np.insert(np.insert(clat,0,2*clat[0]-clat[1]),-1,2*clat[-1]-clat[-2])\n",
    "\n",
    "    lons,lats = np.meshgrid(lon,lat)\n",
    "    chuk_mask = lats>66\n",
    "    return lat,lon,clat,clon,chuk_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7f71fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mld_clim():\n",
    "    \n",
    "    glorys_dir = product_dict['GLORYS12']['dir']\n",
    "    ds_glorys_mask =  xr.open_dataset((glorys_dir + 'glorys_nep_mask.nc'),decode_times=False)\n",
    "    bathym = ds_glorys_mask.deptho.values\n",
    "    \n",
    "    glorys_archive_dir = '/archive/e1n/datasets/GLORYS/monthly_means/'\n",
    "    \n",
    "    first_calc=True\n",
    "    for year in range(1993,2019+1):\n",
    "        print(year)\n",
    "        for month in time_idx:\n",
    "\n",
    "            g_ncfil = glorys_archive_dir + 'GLORYS_REANALYSIS_NEP_' + str(year) + '-' + str(month+1).zfill(2) + '.tmp.nc'\n",
    "            subprocess.run([\"dmget\",f\"{g_ncfil}\"])\n",
    "            g_ds = xr.open_dataset(g_ncfil,decode_times=False)\n",
    "            \n",
    "            # get temperature and salt values\n",
    "            g_temp = g_ds.thetao.values\n",
    "            g_salt = g_ds.so.values\n",
    "            \n",
    "            # calculate potential density for that month and repackage as xarray dataset\n",
    "            pot_density = gsw.density.sigma0(g_salt, g_temp)\n",
    "            potdens_ds = xr.DataArray(pot_density, \n",
    "                          coords=g_ds.coords, \n",
    "                          dims=['time','depth','latitude','longitude'])\n",
    "            \n",
    "            potdens_5m = potdens_ds.interp(depth=5.0)\n",
    "            \n",
    "            if first_calc:\n",
    "                dep_idx = np.argmax(potdens_ds.depth.values>dBM_dep) # starting below 5m depth in search for higher density\n",
    "            arg_max_vals = np.argmax((potdens_ds.values[:,dep_idx:,:,:] >= (potdens_5m.values[:,np.newaxis,:,:]+0.03)),axis=1)+dep_idx\n",
    "            depth_sum = np.sum((potdens_ds.values[:,dep_idx:,:,:] >= (potdens_5m.values[:,np.newaxis,:,:]+0.03)),axis=1)\n",
    "\n",
    "            dens_top = np.squeeze(np.take_along_axis(potdens_ds.values, (arg_max_vals[:,np.newaxis,:,:]-1), axis=1))\n",
    "            dens_bot = np.squeeze(np.take_along_axis(potdens_ds.values, (arg_max_vals[:,np.newaxis,:,:]), axis=1))\n",
    "\n",
    "            depth = potdens_ds.depth.values\n",
    "            z_top = (depth[arg_max_vals-1]).squeeze()\n",
    "            z_bot = (depth[arg_max_vals]).squeeze()\n",
    "\n",
    "            delta_dens = dens_bot-dens_top\n",
    "            delta_z = depth[arg_max_vals] - depth[arg_max_vals-1]\n",
    "\n",
    "            # calculating depth below upper layer given the slope, delta_dens/delta_z_l, between layers above and below\n",
    "            # rho@5m +0.03 kg/m3\n",
    "            mld = z_top + (((potdens_5m.values+0.03) - dens_top)/(delta_dens))*delta_z\n",
    "\n",
    "            # anywhere there were no depth layers that met the +0.03 criteria, set mld to bottom depth because \n",
    "            # water column is effectively homogeonous with rho@5m\n",
    "            mld[depth_sum==0] =  np.tile(bathym[np.newaxis,:,:],(mld.shape[0],1,1))[depth_sum==0]\n",
    "    \n",
    "            if first_calc:\n",
    "                mld_stor = mld\n",
    "                lat,lon,clat,clon,chuk_mask = get_coords(comp_prod,g_ds)\n",
    "                \n",
    "                first_calc = False\n",
    "                \n",
    "            else:\n",
    "                mld_stor = np.append(mld_stor,mld,axis=0)\n",
    "    \n",
    "    # generate climatologies\n",
    "    mld_clim = np.mean(mld_stor.reshape((-1,len(time_idx),mld_stor.shape[1],mld_stor.shape[2])),axis=0)\n",
    "    \n",
    "    return lat,lon,clat,clon,chuk_mask,mld_clim  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffde89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEP Grid\n",
    "nep_grd_fil = '/work/role.medgrp/NEP/plotting/shared_files/NEP_ocean_static_nomask.nc'\n",
    "grd_fid = nc.Dataset(nep_grd_fil)\n",
    "\n",
    "# Extracting tracer lat/lon from the supergrid\n",
    "nep_lat = grd_fid.variables['geolat'][:]\n",
    "nep_lon = grd_fid.variables['geolon'][:]\n",
    "\n",
    "# Extracting tracer corner lat/lon from the supergrid - needed for regridding and pcolor plots\n",
    "nep_clat = grd_fid.variables['geolat_c'][:]\n",
    "nep_clon = grd_fid.variables['geolon_c'][:]\n",
    "\n",
    "nep_topo = grd_fid.variables['deptho'][:]\n",
    "\n",
    "lsm = grd_fid.variables['wet'][:]\n",
    "lsm[lsm<1]=0 \n",
    "lsm[lsm>1]=1 \n",
    "\n",
    "nep_area = grd_fid.variables['areacello'][:].squeeze()\n",
    "nep_area[lsm<.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27dda91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deBoyer_dir = './'\n",
    "\n",
    "e1n_dir = './'\n",
    "\n",
    "season_dict = {'mean':{'vmin':10,'vmax':90,  'cbar_n':17, 'inc':10, 'dif_range':32, 'dif_cbar_n':25, 'dif_inc':8}}\n",
    "\n",
    "plot_labels = ['a','b','c','d','e','f']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e226c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict = {'NEP':{'dir':f'/work/Utheri.Wagura/NEP/plotting/Figure_4/{experiment}/', \n",
    "                       'ncfil':'nep_MLD_003_1993-2019_clim.nc','mld_var':'MLD_003'},\n",
    "                'dBM':{'dir':'/work/role.medgrp/NEP/plotting/Figure_4/',\n",
    "                        'ncfil':'mld_dr003_ref5m_v2024.nc','mld_var':'mld_dr003'},\n",
    "                'GLORYS12':{'dir':'/work/role.medgrp/NEP/plotting/Figure_4/',\n",
    "                          'ncfil':['']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfadf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/Utheri.Wagura/NEP/plotting/Figure_4/diurnal/nep_MLD_003_1993-2019_clim.nc\n",
      "/work/role.medgrp/NEP/plotting/Figure_4/mld_dr003_ref5m_v2024.nc\n",
      "MEAN BIAS: -6.3996492775408385\n",
      "AREA-WEIGHTED MEAN BIAS: -6.860400019576801\n",
      "RMSE: 11.586383973536234\n",
      "AREA-WEIGHTED RMSE: 11.85438763782122\n",
      "MEDIAN ABSOLUTE ERROR: 6.510428082571206\n",
      "CORRELATION: PearsonRResult(statistic=0.746356777059585, pvalue=0.0)\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n"
     ]
    }
   ],
   "source": [
    "stats_box_props = dict(boxstyle=\"square\", fc=\"w\", ec=\"0.0\", alpha=1)   \n",
    "print_stats = True\n",
    "const_offset = 500\n",
    "plot_GLORYS = True\n",
    "annotate_plots = True\n",
    "\n",
    "if plot_GLORYS:\n",
    "    comp_prods =  ['dBM', 'GLORYS12']\n",
    "    fig_nrows=2\n",
    "    fig_ht = 14 \n",
    "else:\n",
    "    comp_prods = ['dBM']\n",
    "    fig_nrows=1\n",
    "    fig_ht = 7\n",
    "    \n",
    "dBM_dep = 5.0\n",
    "ds_nep = get_ds('NEP')\n",
    "\n",
    "for tim_frame, time_idx in zip(['mean'],[np.arange(12)]):\n",
    "\n",
    "    nrow = 0\n",
    "    nlab = 0\n",
    "    \n",
    "    fig = plt.figure(figsize=(26,fig_ht),dpi=300)\n",
    "    widths = [10,10,.1,10]\n",
    "    spec = fig.add_gridspec(ncols=4, nrows=fig_nrows,wspace=0,hspace=0.,width_ratios=widths) \n",
    "    \n",
    "    for comp_prod in comp_prods:\n",
    "        ncol = 0\n",
    "        nep_mld = ds_nep[product_dict['NEP']['mld_var']].values[time_idx,:]\n",
    "        #print(nep_mld.shape)\n",
    "        if comp_prod == 'dBM':\n",
    "            ds_ref = get_ds(comp_prod)\n",
    "            lat,lon,clat,clon,chuk_mask = get_coords(comp_prod,ds_ref)\n",
    "            ref_mld = ds_ref[product_dict[comp_prod]['mld_var']].values[time_idx,:]\n",
    "            \n",
    "            # create regrid object: NEP -> dBM\n",
    "            sourcefield, destfield, regrid = create_regrid_obj(nep_clon,nep_clat,lsm,clon,clat)\n",
    "            \n",
    "            nep_val_out = np.zeros((len(time_idx),len(lat),len(lon)))\n",
    "            for nt in range(len(time_idx)):\n",
    "                sourcefield.data[...] = nep_mld[nt,:].squeeze() + const_offset \n",
    "                destfield = regrid(sourcefield, destfield)\n",
    "                tmp_val = copy.deepcopy(destfield.data)\n",
    "                tmp_val[tmp_val==0] = np.nan\n",
    "                nep_val_out[nt,:] = tmp_val - const_offset\n",
    "               \n",
    "            sourcefield.data[...] = lsm + const_offset\n",
    "            destfield = regrid(sourcefield, destfield)\n",
    "            tmp_val = copy.deepcopy(destfield.data)\n",
    "            tmp_val[tmp_val==0] = np.nan\n",
    "            lsm_out = tmp_val - const_offset\n",
    "            lsm_out[lsm_out>.5]=1\n",
    "            lsm_out[lsm_out<.5]=0\n",
    "            \n",
    "            comp_diff_val = copy.deepcopy(ref_mld)\n",
    "            comp_diff_val = np.mean(comp_diff_val,axis=0)\n",
    "            # remove chukchi sea\n",
    "            comp_diff_val[chuk_mask] = np.nan\n",
    "            # remove values outside NEP domain\n",
    "            comp_diff_val[lsm_out==0] = np.nan\n",
    "                \n",
    "            nep_diff_val = copy.deepcopy(nep_val_out)\n",
    "            nep_diff_val = np.mean(nep_diff_val,axis=0)\n",
    "            # remove chukchi sea\n",
    "            nep_diff_val[chuk_mask] = np.nan\n",
    "            # remove values outside NEP domain\n",
    "            nep_diff_val[lsm_out==0] = np.nan \n",
    "                \n",
    "            # Get area for weighted statistics \n",
    "            sourcefield.data[...] = nep_area + const_offset\n",
    "            destfield = regrid(sourcefield, destfield)\n",
    "            tmp_val = copy.deepcopy(destfield.data)\n",
    "            tmp_val[tmp_val==0] = np.nan\n",
    "            area_out = tmp_val - const_offset\n",
    "            \n",
    "            dif_clon = clon; dif_clat = clat\n",
    "            dif_lon = lon; dif_lat = lat\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            lat,lon,clat,clon,chuk_mask,ref_mld = calc_mld_clim()\n",
    "            ref_lsm = ~np.isnan(ref_mld[0,:].squeeze())\n",
    "            \n",
    "            # create regrid object: GLORYS -> NEP\n",
    "            sourcefield, destfield, regrid = create_regrid_obj(clon,clat,ref_lsm,nep_clon,nep_clat)\n",
    "                \n",
    "            # regrid GLORYS to NEP\n",
    "            nt1,nj,ni = nep_mld.shape\n",
    "            comp_val_out = np.zeros((nt1,nj,ni))\n",
    "            for nt in range(nt1):\n",
    "                sourcefield.data[...] = ref_mld[nt,:].squeeze() + const_offset\n",
    "                destfield = regrid(sourcefield, destfield)\n",
    "                tmp_val = copy.deepcopy(destfield.data)\n",
    "                tmp_val[tmp_val==0] = np.nan\n",
    "                comp_val_out[nt,:] = tmp_val - const_offset\n",
    "        \n",
    "            comp_diff_val = copy.deepcopy(comp_val_out)\n",
    "            comp_diff_val = np.mean(comp_diff_val,axis=0)\n",
    "            comp_diff_val[nep_lat>66] = np.nan\n",
    "            comp_diff_val[lsm==0] = np.nan\n",
    "                \n",
    "            nep_diff_val = copy.deepcopy(nep_mld)\n",
    "            nep_diff_val = np.mean(nep_diff_val,axis=0)\n",
    "            nep_diff_val[nep_lat>66] = np.nan\n",
    "            nep_diff_val[lsm==0] = np.nan\n",
    "        \n",
    "            area_out = copy.deepcopy(nep_area)\n",
    "            dif_clon = nep_clon; dif_clat = nep_clat\n",
    "            dif_lon = nep_lon; dif_lat = nep_lat\n",
    "                    \n",
    "        ref_mld = np.nanmean(ref_mld,axis=0)\n",
    "        nep_mld = np.nanmean(nep_mld,axis=0)\n",
    "        \n",
    "        ref_mld[chuk_mask] = np.nan\n",
    "        nep_mld[nep_lat>66] = np.nan   \n",
    "\n",
    "        # Colorbars\n",
    "        cmap2 = cmocean.cm.balance\n",
    "        bounds = np.linspace(-season_dict[tim_frame]['dif_range'],\n",
    "                         season_dict[tim_frame]['dif_range'],\n",
    "                         season_dict[tim_frame]['cbar_n'])\n",
    "        norm2 = mcolors.BoundaryNorm(bounds, cmap2.N, extend='both')\n",
    "\n",
    "        cmap1 = 'pyart_HomeyerRainbow'\n",
    "        bounds = np.linspace(season_dict[tim_frame]['vmin'],\n",
    "                         season_dict[tim_frame]['vmax'],\n",
    "                         season_dict[tim_frame]['dif_cbar_n'])\n",
    "        norm1 = mcolors.BoundaryNorm(bounds, 256, extend='both')\n",
    "\n",
    "        plot_mld(nep_clon,nep_clat,nep_lon,nep_lat,nep_mld,\n",
    "             season_dict[tim_frame]['vmin'],season_dict[tim_frame]['vmax'],\n",
    "             cmap1,norm1,season_dict[tim_frame]['inc'])\n",
    "\n",
    "        ncol+=1\n",
    "        nlab+=1\n",
    "\n",
    "        plot_mld(clon,clat,lon,lat,ref_mld,\n",
    "             season_dict[tim_frame]['vmin'],season_dict[tim_frame]['vmax'],\n",
    "             cmap1,norm1,season_dict[tim_frame]['inc'])\n",
    "\n",
    "        ncol+=2\n",
    "        nlab+=1\n",
    "    \n",
    "        # CALCULATE STATISTICS\n",
    "        mean_bias, rmse, medae, corr = calc_stats(nep_diff_val,comp_diff_val,area_out)\n",
    "\n",
    "        plot_mld(dif_clon,dif_clat,dif_lon,dif_lat,nep_diff_val-comp_diff_val,\n",
    "                 -season_dict[tim_frame]['dif_range'],season_dict[tim_frame]['dif_range'],\n",
    "                 cmap2,norm2,season_dict[tim_frame]['dif_inc'])\n",
    "        nlab+=1\n",
    "        \n",
    "        fig_str = f'/work/Utheri.Wagura/NEP/plotting/Figure_4/{experiment}/Figure4_NEP_dBM_2024_GLORYS_mld_comp_1993-2019_mean'\n",
    "    \n",
    "        nrow+=1\n",
    "    plt.savefig(fig_str)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "role_medpy311",
   "language": "python",
   "name": "role_medpy311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
